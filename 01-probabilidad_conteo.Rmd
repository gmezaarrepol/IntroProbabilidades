
# Probabilidad y Conteo

Suerte. Coincidencia. Aleatoriedad. Incertidumbre. Riesgo. Duda. Fortuna. Oportunidad.
Probablemente hayas escuchado estas palabras innumerables veces, pero es probable que se hayan usado de una manera vaga y casual. Desafortunadamente, a pesar de su ubicuidad en la ciencia y en la vida cotidiana, la probabilidad puede ser profundamente contradictoria. Si confiamos en intuiciones de dudosa validez, corremos un serio riesgo de hacer predicciones inexactas o decisiones demasiado seguras. El objetivo de este libro es introducir la probabilidad como un marco lógico para cuantificar la incertidumbre y la aleatoriedad de una manera basada en principios. También intentaremos fortalecer la intuición, tanto cuando nuestras suposiciones iniciales coincidan con el razonamiento lógico como cuando no tengamos tanta suerte.

***

## ¿Por qué estudiar probabilidad?

Las matemáticas son la lógica de la certeza; la probabilidad es la lógica de la incertidumbre. La probabilidad es extremadamente útil en una amplia variedad de campos, ya que proporciona herramientas para comprender y explicar la variación, separar la señal del ruido y modelar fenómenos complejos. Para dar solo una pequeña muestra de una lista de aplicaciones en continuo crecimiento:

1. Estadísticas: la probabilidad es la base y el lenguaje de las estadísticas, lo que permite muchos métodos poderosos para usar datos para aprender sobre el mundo.

2. Física: Einstein dijo la famosa frase "Dios no juega a los dados con el universo", pero la comprensión actual de la física cuántica implica en gran medida la probabilidad en el nivel más fundamental de la naturaleza. La mecánica estadística es otra rama importante de la física que se basa en la probabilidad.

3. Biología: La genética está profundamente entrelazada con la probabilidad, tanto en la herencia de genes como en el modelado de mutaciones aleatorias.

4. Ciencias de la computación: Los algoritmos aleatorios toman decisiones aleatorias mientras se ejecutan, y en muchas aplicaciones importantes son más simples y más eficientes que cualquier alternativa determinista actualmente conocida. La probabilidad también juega un papel esencial en el estudio del rendimiento de los algoritmos y en el machine learning y la inteligencia artificial.

5. Meteorología: Los pronósticos meteorológicos se calculan (o deberían) calcularse y expresarse en términos de probabilidad.

6. Juegos de azar: muchas de las primeras investigaciones sobre la probabilidad tenían como objetivo responder preguntas sobre el juego y los juegos de azar.

7. Finanzas: a riesgo de redundancia con el ejemplo anterior, conviene señalar que la probabilidad es fundamental en las finanzas cuantitativas. El modelado de los precios de las acciones a lo largo del tiempo y la determinación de precios "justos" para los instrumentos financieros se basan en gran medida en la probabilidad.

8. Ciencias políticas: En los últimos años, las ciencias políticas se han vuelto cada vez más cuantitativas y estadísticas, con aplicaciones como el análisis de encuestas de opinión pública, la evaluación de la manipulación y la predicción de elecciones.

9. Medicina: el desarrollo de ensayos clínicos aleatorizados, en los que los pacientes son asignados al azar para recibir tratamiento o placebo, ha transformado la investigación médica en los últimos años. Como señaló el bioestadístico David Harrington, “Algunos han conjeturado que podría ser el avance más significativo en la medicina científica en el siglo XX ... En una de las deliciosas ironías de la ciencia moderna, el ensayo aleatorio se 'ajusta' tanto a lo observado como a lo observado. heterogeneidad no observada en un experimento controlado al introducir una variación aleatoria en el diseño del estudio ". 

10. Vida: la vida es incierta y la probabilidad es la lógica de la incertidumbre. Si bien no es práctico realizar un cálculo de probabilidad formal para cada decisión tomada en la vida, pensar detenidamente en la probabilidad puede ayudarnos a evitar algunas falacias comunes, arrojar luz sobre las coincidencias y hacer mejores predicciones.

La probabilidad proporciona procedimientos para la resolución de problemas basados en principios, pero también puede producir dificultades y paradojas. Por ejemplo, veremos en este capítulo que incluso Gotfried Wilhelm von Leibniz y Sir Isaac Newton, las dos personas que descubrieron independientemente el cálculo en el siglo XVII, no fueron inmunes a los errores básicos de probabilidad. A lo largo de este libro, utilizaremos las siguientes estrategias para ayudar a evitar posibles problemas.

1. Simulación: Un aspecto hermoso de la probabilidad es que a menudo es posible estudiar problemas a través de la simulación. En lugar de debatir interminablemente una respuesta con alguien que no está de acuerdo contigo, puedes ejecutar una simulación y ver empíricamente quién tiene la razón. Cada capítulo de este libro termina con una sección que ofrece ejemplos de cómo realizar cálculos y simulaciones en R, un entorno informático estadístico gratuito.

2. Riesgos biológicos: Estudiar los errores comunes es importante para obtener una mejor comprensión de lo que es y no es un razonamiento válido en probabilidad. En este libro, los errores comunes se denominan riesgos biológicos y se indican con (X) (¡ya que cometer tales errores puede ser peligroso para la salud!).

3. Verificaciones de cordura: después de resolver un problema de una manera, a menudo intentaremos resolver el mismo problema de una manera diferente o examinar si nuestra respuesta tiene sentido en casos simples y extremos.

***

## Espacios de muestra y Pebble World

El marco matemático para la probabilidad se basa en conjuntos. Imagine que se realiza un experimento, lo que da como resultado uno de un conjunto de posibles resultados. Antes de realizar el experimento, se desconoce qué resultado será el resultado; después, el resultado "cristaliza" en el resultado real.

::: {.definition #pyth name="Espacio muestral y evento"}
El espacio muestral S de un experimento es el conjunto de todos los posibles resultados del experimento. Un evento A es un subconjunto del espacio muestral S, y decimos que A ocurrió si el resultado real está en A.
:::

```{r 1_1, out.width='50%', echo = FALSE, fig.align='center', fig.cap='Un espacio muestral como Pebble World, con dos eventos A y B destacados'}
knitr::include_graphics(rep("images/1_1.png"))
```

El espacio muestral de un experimento puede ser finito, infinito numerable o infinito incontable (consulte la Sección A.1.5 del apéndice matemático para obtener una explicación de los conjuntos contables e incontables). Cuando el espacio muestral es finito, podemos visualizarlo como Pebble World, como se muestra en la Figura 1.1. Cada pebble representa un resultado y un evento es un conjunto de pebbles.

Realizar el experimento equivale a seleccionar al azar un pebble. Si todos los pebbles tienen la misma masa, es igualmente probable que se elijan todos los pebbles. Este caso especial es el tema de las próximas dos secciones. En la sección 1.6, damos una definición general de probabilidad que permite que los pebbles difieran en masa.

La teoría de conjuntos es muy útil en probabilidad, ya que proporciona un lenguaje rico para expresar y trabajar con eventos; La sección A.1 del apéndice de matemáticas proporciona una revisión de la teoría de conjuntos. Las operaciones de conjunto, especialmente uniones, intersecciones y complementos, facilitan la construcción de nuevos eventos en términos de eventos ya definidos. Estos conceptos también nos permiten expresar un evento de más de una forma; A menudo, es mucho más fácil trabajar con una expresión para un evento que con otra expresión para el mismo evento.

Por ejemplo, sea $S$ el espacio muestral de un experimento y sean $A, B \subseteq S$ eventos. Entonces la unión $A \cup B$ es el evento que ocurre si y solo si ocurre al menos uno de $A, B$, la intersección $A \cap B$ es el evento que ocurre si y solo si ocurren $A y B$, y el complemento $A^c$ es el evento que ocurre si y solo si $A$ no ocurre. También tenemos las leyes de De Morgan:

$$ (A \cup B)^c = A^c \cap B^c \: and \: (A \cap B)^c = A^c \cup B^c $$
ya que decir que no es el caso de que al menos uno de A y B ocurra es lo mismo que decir que A no ocurre y B no ocurre, y decir que no es el caso de que ocurran ambos es lo mismo que decir que al menos uno no ocurre. Resultados análogos son válidos para uniones e intersecciones de más de dos eventos.
